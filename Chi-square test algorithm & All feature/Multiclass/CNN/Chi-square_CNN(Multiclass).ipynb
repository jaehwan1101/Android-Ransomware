{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_and_labels(data_folder, num_classes, img_size=(28, 28), color_mode='grayscale'):\n",
    "    X = []\n",
    "    y_onehot = []\n",
    "    \n",
    "    for idx, class_folder in enumerate(sorted(os.listdir(data_folder))):\n",
    "        class_path = os.path.join(data_folder, class_folder)\n",
    "        \n",
    "        for img_name in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            img = load_img(img_path, target_size=img_size, color_mode=color_mode)\n",
    "            X.append(img_to_array(img))\n",
    "            \n",
    "            onehot = np.zeros(num_classes)\n",
    "            onehot[idx] = 1\n",
    "            y_onehot.append(onehot)\n",
    "    \n",
    "    return np.array(X) / 255.0, np.array(y_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# 절반씩 줄여보기도 하기\n",
    "\n",
    "def create_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Convolution 1\n",
    "    model.add(layers.Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    # Maxpooling 1\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Convolution 2\n",
    "    model.add(layers.Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    # Maxpooling 2\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Convolution 3\n",
    "    model.add(layers.Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    # Maxpooling 3\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Flatten\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    # FC 1\n",
    "    model.add(layers.Dense(2048, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    # FC 2\n",
    "    model.add(layers.Dense(2048, activation='relu')) \n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    # FC 3 (출력층)\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', 'AUC'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 28s 9ms/step - loss: 1.7935 - accuracy: 0.5005 - auc: 0.7848 - val_loss: 1.7569 - val_accuracy: 0.5028 - val_auc: 0.7989\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.7296 - accuracy: 0.5069 - auc: 0.8072 - val_loss: 1.6953 - val_accuracy: 0.5129 - val_auc: 0.8182\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.6863 - accuracy: 0.5128 - auc: 0.8208 - val_loss: 1.6666 - val_accuracy: 0.5149 - val_auc: 0.8280\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.6659 - accuracy: 0.5146 - auc: 0.8272 - val_loss: 1.6545 - val_accuracy: 0.5167 - val_auc: 0.8328\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.6529 - accuracy: 0.5163 - auc: 0.8313 - val_loss: 1.6429 - val_accuracy: 0.5170 - val_auc: 0.8346\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.6422 - accuracy: 0.5170 - auc: 0.8347 - val_loss: 1.6365 - val_accuracy: 0.5178 - val_auc: 0.8374\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.6307 - accuracy: 0.5181 - auc: 0.8386 - val_loss: 1.6150 - val_accuracy: 0.5204 - val_auc: 0.8429\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 23s 9ms/step - loss: 1.6200 - accuracy: 0.5191 - auc: 0.8413 - val_loss: 1.6064 - val_accuracy: 0.5208 - val_auc: 0.8456\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.6130 - accuracy: 0.5189 - auc: 0.8435 - val_loss: 1.6020 - val_accuracy: 0.5206 - val_auc: 0.8457\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.6065 - accuracy: 0.5201 - auc: 0.8453 - val_loss: 1.5927 - val_accuracy: 0.5235 - val_auc: 0.8485\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.6022 - accuracy: 0.5203 - auc: 0.8465 - val_loss: 1.5911 - val_accuracy: 0.5223 - val_auc: 0.8496\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.5980 - accuracy: 0.5207 - auc: 0.8475 - val_loss: 1.5906 - val_accuracy: 0.5224 - val_auc: 0.8500\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 23s 9ms/step - loss: 1.5936 - accuracy: 0.5213 - auc: 0.8488 - val_loss: 1.5820 - val_accuracy: 0.5232 - val_auc: 0.8519\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.5892 - accuracy: 0.5221 - auc: 0.8499 - val_loss: 1.5712 - val_accuracy: 0.5234 - val_auc: 0.8540\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.5818 - accuracy: 0.5222 - auc: 0.8517 - val_loss: 1.5794 - val_accuracy: 0.5230 - val_auc: 0.8525\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.5781 - accuracy: 0.5232 - auc: 0.8526 - val_loss: 1.5698 - val_accuracy: 0.5239 - val_auc: 0.8544\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.5735 - accuracy: 0.5229 - auc: 0.8538 - val_loss: 1.5633 - val_accuracy: 0.5251 - val_auc: 0.8557\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.5682 - accuracy: 0.5239 - auc: 0.8549 - val_loss: 1.5569 - val_accuracy: 0.5243 - val_auc: 0.8580\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.5637 - accuracy: 0.5238 - auc: 0.8560 - val_loss: 1.5576 - val_accuracy: 0.5254 - val_auc: 0.8574\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.5605 - accuracy: 0.5245 - auc: 0.8567 - val_loss: 1.5533 - val_accuracy: 0.5256 - val_auc: 0.8584\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.5577 - accuracy: 0.5244 - auc: 0.8574 - val_loss: 1.5597 - val_accuracy: 0.5245 - val_auc: 0.8573\n",
      "Epoch 22/50\n",
      "2500/2500 [==============================] - 23s 9ms/step - loss: 1.5543 - accuracy: 0.5252 - auc: 0.8580 - val_loss: 1.5535 - val_accuracy: 0.5246 - val_auc: 0.8590\n",
      "Epoch 23/50\n",
      "2500/2500 [==============================] - 23s 9ms/step - loss: 1.5517 - accuracy: 0.5253 - auc: 0.8588 - val_loss: 1.5509 - val_accuracy: 0.5256 - val_auc: 0.8589\n",
      "Epoch 24/50\n",
      "2500/2500 [==============================] - 23s 9ms/step - loss: 1.5497 - accuracy: 0.5256 - auc: 0.8592 - val_loss: 1.5720 - val_accuracy: 0.5256 - val_auc: 0.8553\n",
      "Epoch 25/50\n",
      "2500/2500 [==============================] - 23s 9ms/step - loss: 1.5479 - accuracy: 0.5257 - auc: 0.8596 - val_loss: 1.5414 - val_accuracy: 0.5278 - val_auc: 0.8609\n",
      "Epoch 26/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.5479 - accuracy: 0.5258 - auc: 0.8596 - val_loss: 1.5509 - val_accuracy: 0.5268 - val_auc: 0.8592\n",
      "Epoch 27/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.5431 - accuracy: 0.5261 - auc: 0.8607 - val_loss: 1.5416 - val_accuracy: 0.5263 - val_auc: 0.8610\n",
      "Epoch 28/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.5430 - accuracy: 0.5263 - auc: 0.8607 - val_loss: 1.5386 - val_accuracy: 0.5275 - val_auc: 0.8615\n",
      "Epoch 29/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.5429 - accuracy: 0.5267 - auc: 0.8606 - val_loss: 1.5377 - val_accuracy: 0.5266 - val_auc: 0.8616\n",
      "Epoch 30/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.5391 - accuracy: 0.5272 - auc: 0.8615 - val_loss: 1.5409 - val_accuracy: 0.5257 - val_auc: 0.8613\n",
      "Epoch 31/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.5379 - accuracy: 0.5275 - auc: 0.8618 - val_loss: 1.5331 - val_accuracy: 0.5263 - val_auc: 0.8633\n",
      "Epoch 32/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.5349 - accuracy: 0.5279 - auc: 0.8624 - val_loss: 1.5305 - val_accuracy: 0.5298 - val_auc: 0.8633\n",
      "Epoch 33/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.5340 - accuracy: 0.5282 - auc: 0.8626 - val_loss: 1.5367 - val_accuracy: 0.5293 - val_auc: 0.8618\n",
      "Epoch 34/50\n",
      "2500/2500 [==============================] - 23s 9ms/step - loss: 1.5326 - accuracy: 0.5283 - auc: 0.8628 - val_loss: 1.5544 - val_accuracy: 0.5255 - val_auc: 0.8601\n",
      "Epoch 35/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.5316 - accuracy: 0.5281 - auc: 0.8632 - val_loss: 1.5341 - val_accuracy: 0.5295 - val_auc: 0.8634\n",
      "Epoch 36/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.5300 - accuracy: 0.5287 - auc: 0.8634 - val_loss: 1.5283 - val_accuracy: 0.5289 - val_auc: 0.8637\n",
      "Epoch 37/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.5292 - accuracy: 0.5288 - auc: 0.8635 - val_loss: 1.5285 - val_accuracy: 0.5280 - val_auc: 0.8636\n",
      "Epoch 38/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.5268 - accuracy: 0.5295 - auc: 0.8641 - val_loss: 1.5299 - val_accuracy: 0.5278 - val_auc: 0.8639\n",
      "Epoch 39/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.5261 - accuracy: 0.5295 - auc: 0.8644 - val_loss: 1.5297 - val_accuracy: 0.5287 - val_auc: 0.8636\n",
      "Epoch 40/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.5261 - accuracy: 0.5292 - auc: 0.8643 - val_loss: 1.5269 - val_accuracy: 0.5287 - val_auc: 0.8645\n",
      "Epoch 41/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.5243 - accuracy: 0.5297 - auc: 0.8647 - val_loss: 1.5252 - val_accuracy: 0.5285 - val_auc: 0.8645\n",
      "Epoch 42/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.5222 - accuracy: 0.5300 - auc: 0.8651 - val_loss: 1.5203 - val_accuracy: 0.5319 - val_auc: 0.8653\n",
      "Epoch 43/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.5228 - accuracy: 0.5304 - auc: 0.8649 - val_loss: 1.5236 - val_accuracy: 0.5305 - val_auc: 0.8648\n",
      "Epoch 44/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.5229 - accuracy: 0.5303 - auc: 0.8650 - val_loss: 1.5318 - val_accuracy: 0.5304 - val_auc: 0.8626\n",
      "Epoch 45/50\n",
      "2500/2500 [==============================] - 23s 9ms/step - loss: 1.5209 - accuracy: 0.5305 - auc: 0.8653 - val_loss: 1.5274 - val_accuracy: 0.5310 - val_auc: 0.8643\n",
      "Epoch 46/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.5190 - accuracy: 0.5310 - auc: 0.8657 - val_loss: 1.5245 - val_accuracy: 0.5293 - val_auc: 0.8647\n",
      "Epoch 47/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.5186 - accuracy: 0.5311 - auc: 0.8658 - val_loss: 1.5212 - val_accuracy: 0.5320 - val_auc: 0.8654\n",
      "Epoch 48/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.5186 - accuracy: 0.5305 - auc: 0.8659 - val_loss: 1.5227 - val_accuracy: 0.5297 - val_auc: 0.8653\n",
      "Epoch 49/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.5180 - accuracy: 0.5310 - auc: 0.8661 - val_loss: 1.5224 - val_accuracy: 0.5322 - val_auc: 0.8649\n",
      "Epoch 50/50\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.5168 - accuracy: 0.5313 - auc: 0.8663 - val_loss: 1.5253 - val_accuracy: 0.5312 - val_auc: 0.8648\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.5289 - accuracy: 0.5304 - auc: 0.8640\n",
      "Test Loss: 1.5289483070373535\n",
      "Test Accuracy: 0.5304499864578247\n",
      "Test AUC: 0.8640185594558716\n",
      "Test Duration: 4.3618 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import time\n",
    "\n",
    "# 데이터 경로\n",
    "base_path = r'C:\\Users\\pc\\Desktop\\CNN\\36_feature_multiclass_CNN'\n",
    "train_data_folder = os.path.join(base_path, 'Train_Image')\n",
    "val_data_folder = os.path.join(base_path, 'Validation_Image')\n",
    "test_data_folder = os.path.join(base_path, 'Test_Image')\n",
    "\n",
    "num_classes = 11\n",
    "\n",
    "# 데이터 로드\n",
    "X_train, y_train_onehot = load_data_and_labels(train_data_folder, num_classes)\n",
    "X_val, y_val_onehot = load_data_and_labels(val_data_folder, num_classes)\n",
    "X_test, y_test_onehot = load_data_and_labels(test_data_folder, num_classes)\n",
    "\n",
    "# 모델 생성\n",
    "input_shape = X_train[0].shape\n",
    "model = create_model(input_shape, num_classes)\n",
    "\n",
    "# 모델 학습을 위한 배치 사이즈를 설정\n",
    "batch_size = 128  # 로 고정하는게 좋을 것 같음\n",
    "\n",
    "# 모델 학습\n",
    "epochs = 50\n",
    "history = model.fit(X_train, y_train_onehot, batch_size=batch_size, validation_data=(X_val, y_val_onehot), epochs=epochs)\n",
    "\n",
    "# 시간 측정 시작\n",
    "start_time = time.time()\n",
    "\n",
    "# 모델 평가\n",
    "test_loss, test_accuracy, test_auc = model.evaluate(X_test, y_test_onehot)\n",
    "\n",
    "# 시간 측정 종료\n",
    "end_time = time.time()\n",
    "\n",
    "# 걸린 시간 계산\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Test AUC:\", test_auc)\n",
    "print(f\"Test Duration: {elapsed_time:.4f} seconds\")  # 소수점 4자리까지 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "Confusion Matrix:\n",
      "[[19843    16     1    31     0    13    23    14    17    41     1]\n",
      " [ 2008   128     4    26     2    11    35     2     1    30     0]\n",
      " [ 1346    19    10    19     0    11    26     5     0    27     0]\n",
      " [ 2195    17     8   289     1     8    45     3     1    25     1]\n",
      " [ 1366    17    10    22     0     5    28     2     1    22     0]\n",
      " [  122     3     0     0     0   120     1     2     2    35     0]\n",
      " [ 2239    19     7    41     1     9   229     3     0    31     0]\n",
      " [ 2166     3     0     6     0     3     9    83    47    27     6]\n",
      " [ 1865     2     0     1     0     1     5    64    74    35     9]\n",
      " [ 2622     8     0    14     1     7    20    16    17   430     4]\n",
      " [ 1649     0     0     4     0     3     3    80    36    28    12]]\n",
      "Accuracy: 0.53045\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# 모델을 사용하여 테스트 데이터에 대한 예측을 수행합니다.\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # 다중 클래스 분류 문제에서는 가장 높은 확률을 가진 클래스를 선택합니다.\n",
    "\n",
    "# 실제 레이블을 가져옵니다.\n",
    "y_true = np.argmax(y_test_onehot, axis=1)\n",
    "\n",
    "# Confusion Matrix를 생성합니다.\n",
    "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
    "\n",
    "# 정확도를 계산합니다.\n",
    "accuracy = np.trace(conf_matrix) / float(np.sum(conf_matrix))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
